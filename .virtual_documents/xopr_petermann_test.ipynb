%load_ext autoreload
%autoreload 2

import numpy as np
import xarray as xr
import hvplot.xarray
import geoviews as gv
import geoviews.feature as gf
import cartopy.crs as ccrs
import matplotlib.pyplot as plt
import shapely
import scipy.constants
import pandas as pd
import traceback
import geopandas as gpd
import xopr.opr_access
import xopr.geometry

hvplot.extension('bokeh')


# Useful projections
epsg_3413 = ccrs.Stereographic(
    central_latitude=90,  # Tangent at the North Pole
    central_longitude=0,  # Common central meridian
    true_scale_latitude=60 # Latitude where scale is true (or near pole for polar stereo)
)
latlng = ccrs.PlateCarree()
features = gf.ocean.options(scale='50m').opts(projection=epsg_3413) * gf.coastline.options(scale='50m').opts(projection=epsg_3413)


# Establish an OPR session
# You'll probably want to set a cache directory if you're running this locally to speed
# up subsequent requests. You can do other things like customize the STAC API endpoint,
# but you shouldn't need to do that for most use cases.
opr = xopr.opr_access.OPRConnection(cache_dir="/tmp")

# Or you can open a connection without a cache directory (for example, if you're parallelizing
# this on a cloud cluster without persistent storage).
#opr = xopr.OPRConnection()


petermann_gdf = gpd.read_file('./petermann_merged_basin_clip.gpkg')
petermann_gdf = petermann_gdf.dissolve()
peter_geom = petermann_gdf.iloc[0].geometry


peter_latlon = petermann_gdf.to_crs(latlng.proj4_init)
region = peter_latlon.iloc[0].geometry


xopr.geometry.project_geojson(region)


# date_range = ( pd.to_datetime('2008-01-01').to_pydatetime(), pd.to_datetime('2025-01-01').to_pydatetime() )
# date_range[0].to_pydatetime()
date_range = '2008-01-01T00:00:00Z/2025-01-01T00:00:00Z'
stac_items = opr.query_frames(geometry=region, date_range=date_range ,max_items=50)


# Plot a map of our loaded data over the selected region on an EPSG:3031 projection

# Create a GeoViews object for the selected region
region_gv = gv.Polygons(region, crs=latlng).opts(
    color='green',
    line_color='black',
    fill_alpha=0.5,
    projection=epsg_3413,
)
# Plot the frame geometries
frame_lines = []
for item in stac_items.geometry:
    frame_lines.append(gv.Path(item, crs=latlng).opts(
        line_width=2,
        projection=epsg_3413
    ))

(features * region_gv * gv.Overlay(frame_lines)).opts(projection=epsg_3413)


stac_items


stac_items['assets'].iloc[0]


def extract_layer_peak_power(radar_ds, layer_twtt, margin_twtt):
    """
    Extract the peak power of a radar layer within a specified margin around the layer's two-way travel time (TWTT).

    Parameters:
    - radar_ds: xarray Dataset containing radar data.
    - layer_twtt: The two-way travel time of the layer to extract.
    - margin_twtt: The margin around the layer's TWTT to consider for peak power extraction.

    Returns:
    - A DataArray containing the peak power values for the specified layer.
    """
    
    # Ensure that layer_twtt.slow_time matches the radar_ds slow_time
    t_start = np.minimum(radar_ds.slow_time.min(), layer_twtt.slow_time.min())
    t_end = np.maximum(radar_ds.slow_time.max(), layer_twtt.slow_time.max())
    layer_twtt = layer_twtt.sel(slow_time=slice(t_start, t_end))
    radar_ds = radar_ds.sel(slow_time=slice(t_start, t_end))
    #layer_twtt = layer_twtt.interp(slow_time=radar_ds.slow_time, method='nearest')
    layer_twtt = layer_twtt.reindex(slow_time=radar_ds.slow_time, method='nearest', tolerance=pd.Timedelta(seconds=1), fill_value=np.nan)
    
    # Calculate the start and end TWTT for the margin
    start_twtt = layer_twtt - margin_twtt
    end_twtt = layer_twtt + margin_twtt
    
    # Extract the data within the specified TWTT range
    data_within_margin = radar_ds.where((radar_ds.twtt >= start_twtt) & (radar_ds.twtt <= end_twtt), drop=True)

    power_dB = 10 * np.log10(np.abs(data_within_margin.Data))

    # Find the twtt index corresponding to the peak power
    peak_twtt_index = power_dB.argmax(dim='twtt')
    # Convert the index to the actual TWTT value
    peak_twtt = power_dB.twtt[peak_twtt_index]

    # Calculate the peak power in dB
    peak_power = power_dB.isel(twtt=peak_twtt_index)

    # Remove unnecessary dimensions
    peak_twtt = peak_twtt.drop_vars('twtt')
    peak_power = peak_power.drop_vars('twtt')
    
    return peak_twtt, peak_power

def surface_bed_reflection_power(stac_item, opr=xopr.opr_access.OPRConnection()):

    frame = opr.load_frame(stac_item, data_product='CSARP_standard')
    frame = frame.resample(slow_time='5s').mean()

    layers = opr.get_layers(frame, source='auto', include_geometry=False)
    if layers is None:
        return None
    
    # Re-pick surface and bed layers to ensure we're getting the peaks
    speed_of_light_in_ice = scipy.constants.c / np.sqrt(3.17)  # Speed of light in ice (m/s)
    layer_selection_margin_twtt = 50 / speed_of_light_in_ice # approx 50 m margin in ice
    surface_repicked_twtt, surface_power = extract_layer_peak_power(frame, layers["standard:surface"]['twtt'], layer_selection_margin_twtt)
    bed_repicked_twtt, bed_power = extract_layer_peak_power(frame, layers["standard:bottom"]['twtt'], layer_selection_margin_twtt)

    # Create a dataset from surface_repicked_twtt, bed_repicked_twtt, surface_power, and bed_power

    reflectivity_dataset = xr.merge([
        surface_repicked_twtt.rename('surface_twtt'),
        bed_repicked_twtt.rename('bed_twtt'),
        surface_power.rename('surface_power_dB'),
        bed_power.rename('bed_power_dB'),
        ],
        compat='override')

    flight_line_metadata = frame.drop_vars(['Data', 'Surface'])
    reflectivity_dataset = xr.merge([reflectivity_dataset, flight_line_metadata])

    reflectivity_dataset = reflectivity_dataset.drop_dims(['twtt'])  # Remove the twtt dimension since everything has been flattened

    attributes_to_copy = ['season', 'segment', 'doi', 'ror', 'funder_text']
    reflectivity_dataset.attrs = {attr: frame.attrs[attr] for attr in attributes_to_copy if attr in frame.attrs}

    return reflectivity_dataset


reflectivity = surface_bed_reflection_power(stac_items.iloc[0], opr=opr)

fig, ax = plt.subplots(figsize=(8, 4))
reflectivity['surface_power_dB'].plot(ax=ax, x='slow_time', label='Surface')
reflectivity['bed_power_dB'].plot(ax=ax, x='slow_time', label='Bed')
ax.set_ylabel('Power [dB]')
ax.legend()
plt.show()


import dask
from dask.distributed import LocalCluster

client = LocalCluster().get_client()


stac_list = [row for _, row in stac_items.iterrows()]
futures = client.map(surface_bed_reflection_power, stac_list, opr=opr)

# Process results as they complete, capturing exceptions
results = []
for future in dask.distributed.as_completed(futures):
    try:
        result = future.result()
        results.append(result)
    except Exception as e:
        print(traceback.format_exc())


# Create a GeoViews object for the selected region
region_gv = gv.Polygons(region, crs=latlng).opts(
    line_color='black',
    fill_alpha=0,
    projection=epsg_3413,
)

data_lines = []
for ds in results:
    if ds is None:
        continue
    ds['bed_minus_surf'] = ds['bed_power_dB'] - ds['surface_power_dB']
    ds = ds.dropna(dim='slow_time')
    ds = xopr.geometry.project_dataset(ds, target_crs=epsg_3413.to_string())
    sc = ds.hvplot.scatter(x='x', y='y', c='bed_minus_surf',
                           hover_cols=['surface_power_dB', 'bed_power_dB'],
                           cmap='turbo', size=3)
    data_lines.append(sc)

(features * region_gv * gv.Overlay(data_lines)).opts(aspect='equal')


results[3]


fig2, ax2 = plt.subplots()
results[1]['surface_twtt'].plot(ax=ax2, label='surface_twtt')
results[1]['bed_twtt'].plot(ax=ax2, label='bed_twtt')
# ax.set_ylabel('Power [dB]')
ax2.legend()
plt.show()


#frames from manually looking on OPS
ops_frames = ['20100420_02_007', '20100420_03_009']


mask = stac_items.index == 'Data_20100420_03_009'
Data_20100420_03_009 = stac_items[mask]





Data_20100420_03_009['assets']['Data_20100420_03_009']


reflectivity_20100420_03_009 = surface_bed_reflection_power(stac_items.loc['Data_20100420_03_009'], opr=opr)


reflectivity_20100420_03_009


def get_basal_layer_wgs84(stac_item, preloaded_layer=None, opr=xopr.opr_access.OPRConnection()):
    if (preloaded_layer is None) or len(preloaded_layer) < 2:
        layers = opr.get_layers_files(stac_item)
    else:
        layers = preloaded_layer
    
    basal_layer = layers["standard:bottom"]
    surface_layer = layers["standard:surface"]

    surface_wgs84 = layers["standard:surface"]['elev'] - (layers["standard:surface"]['twtt'] * (scipy.constants.c / 2))
    delta_twtt = basal_layer['twtt'] - surface_layer['twtt']
    basal_wgs84 = surface_wgs84 - (delta_twtt * ((scipy.constants.c / np.sqrt(3.15)) / 2))

    basal_layer['wgs84'] = basal_wgs84
    return basal_layer


bed = get_basal_layer_wgs84(stac_items.loc['Data_20100420_03_009'], preloaded_layer=layer_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})





import dask
import dask.delayed as delayed
from dask import compute
from dask.distributed import LocalCluster

client = LocalCluster().get_client()
client


@delayed
def safe_get_layers_db(stac_item, opr=xopr.opr_access.OPRConnection()):
    try:
        retries = 1
        backoff_time = 5
        backoff_jitter = 30
        while retries > 0:
            try:
                return opr.get_layers_db(stac_item)
            except requests.exceptions.RequestException as e:
                sleep_time = backoff_time + np.random.uniform(0, backoff_jitter)
                print(f"Request error fetching layers for {stac_item['id']}: {e}. Retrying in {sleep_time:.1f} seconds...")
                time.sleep(sleep_time)
                retries -= 1
                backoff_time *= 2  # Exponential backoff
    except Exception as e:
        print(f"Error fetching layers for {stac_item['id']}: {e}")
        return None

def get_basal_layer_wgs84(stac_item, preloaded_layer=None, opr=xopr.opr_access.OPRConnection()):
    if (preloaded_layer is None) or len(preloaded_layer) < 2:
        layers = opr.get_layers_files(stac_item)
    else:
        layers = preloaded_layer
    
    basal_layer = layers["standard:bottom"]
    surface_layer = layers["standard:surface"]

    surface_wgs84 = layers["standard:surface"]['elev'] - (layers["standard:surface"]['twtt'] * (scipy.constants.c / 2))
    delta_twtt = basal_layer['twtt'] - surface_layer['twtt']
    basal_wgs84 = surface_wgs84 - (delta_twtt * ((scipy.constants.c / np.sqrt(3.15)) / 2))

    basal_layer['wgs84'] = basal_wgs84
    return basal_layer


@delayed
def compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, layer_1, layer_2):
    """Implementation that receives actual layer values"""
    try:
        bed_1 = get_basal_layer_wgs84(stac_item_1, preloaded_layer=layer_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})
        bed_2 = get_basal_layer_wgs84(stac_item_2, preloaded_layer=layer_2).rename({'lat': 'Latitude', 'lon': 'Longitude'})

        bed_1 = xopr.geometry.project_dataset(bed_1, "EPSG:3031")
        bed_2 = xopr.geometry.project_dataset(bed_2, "EPSG:3031")

        x, y = intersection_geometry.coords[0]

        dist_1 = np.sqrt((bed_1['x'] - x)**2 + (bed_1['y'] - y)**2)
        dist_2 = np.sqrt((bed_2['x'] - x)**2 + (bed_2['y'] - y)**2)

        min_idx_1 = dist_1.argmin().item()
        min_idx_2 = dist_2.argmin().item()

        dist_between_pts = np.sqrt((bed_1['x'][min_idx_1] - bed_2['x'][min_idx_2])**2 + (bed_1['y'][min_idx_1] - bed_2['y'][min_idx_2])**2)

        elev_1 = bed_1['wgs84'][min_idx_1].item()
        elev_2 = bed_2['wgs84'][min_idx_2].item()

        return elev_1, elev_2, dist_between_pts
    except Exception as e:
        print(f"Error in compute_crossover_error: {e}")
        return None, None, None  # Return sentinel values on error

def compute_crossover_error(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1=None, preloaded_layer_2=None):
    """Wrapper that handles delayed objects properly"""
    # These will be delayed objects or None
    return compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1, preloaded_layer_2)


future_db_layers = {}
future_results = {}
for idx, row in intersections.iterrows():
    stac_item_1 = stac_items_df.loc[row['id_1']].to_dict()
    stac_item_2 = stac_items_df.loc[row['id_2']].to_dict()
    stac_item_1['id'] = row['id_1']
    stac_item_2['id'] = row['id_2']

    # Fetch the layers from the database if available
    # Updated to use opr:segment instead of opr:flight (schema change)
    db_key_1 = (row['collection_1'], row['opr:date_1'], row['opr:segment_1'])
    
    if db_key_1 not in future_db_layers:
        future_db_layers[db_key_1] = safe_get_layers_db(stac_item_1)


    # Create delayed task but DON'T compute yet
    r = compute_crossover_error(
        stac_item_1, stac_item_2, row.intersection_geometry,
        preloaded_layer_1=future_db_layers.get(db_key_1),
        preloaded_layer_2=future_db_layers.get(db_key_2)
    )
    future_results[idx] = r  # Store the delayed object, not the computed result


stac_items.loc['Data_20100420_03_009']['properties']


layers = opr.get_layers_files(stac_items.loc['Data_20100420_03_009'])


layers['standard:bottom']


layers


stac_1 = stac_items.loc['Data_20100420_03_009'].to_dict()
frame_1 = opr.load_frame(stac_1)
frame_1 = xopr.radar_util.add_along_track(frame_1)
frame_1 = xopr.radar_util.interpolate_to_vertical_grid(frame_1, vertical_coordinate='wgs84')

frame_1_proj = xopr.geometry.project_dataset(frame_1, "EPSG:3413")
# layers_1 = opr.get_layers(frame_1)


# bed_1 = get_basal_layer_wgs84(stac_item_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})


frame_1_proj


layers_1 = opr.get_layers(frame_1)



for layer_idx in layers_1:
    layers_1[layer_idx] = xopr.radar_util.add_along_track(layers_1[layer_idx])
    layers_1[layer_idx] = xopr.layer_twtt_to_range(layers_1[layer_idx], layers_1["standard:surface"], vertical_coordinate='wgs84')
    layers_1[layer_idx] = xopr.layer_twtt_to_range(layers_1[layer_idx], layers_1["standard:surface"], vertical_coordinate='range')


layers_1['standard:bottom']


clb_min_pct, clb_max_pct = 30, 97

# Plot radargrams in elevation coordinates with layers
fig, (ax1) = plt.subplots(1, 1, figsize=(15, 8))

# Frame 1 radargram in elevation
pwr_1_elev = 10*np.log10(np.abs(frame_1.Data))
vmax_1 = np.percentile(pwr_1_elev, clb_max_pct)
vmin_1 = np.percentile(pwr_1_elev, clb_min_pct)
pwr_1_elev.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax1, vmin=vmin_1, vmax=vmax_1)
# ax1.axvline(frame_1.along_track[idx_1].values, color='red', linestyle='--', linewidth=2, label='Crossover')

# Plot layers using elevation data
for layer_name in layers_1:
    layers_1[layer_name]['wgs84'].plot(ax=ax1, x='along_track', linewidth=1, linestyle=':', label=layer_name)

# ax1.set_title(f"{intersect['collection_1']} - {intersect['id_1']} (Elevation view)")
ax1.set_ylabel('Elevation (m)')
ax1.legend()


pwr_1_elev


fig.savefig(f"Petermann_{frame_1.attrs['granule']}.png", dpi=300)


frame_1.attrs['granule']


# Plot layers using elevation data
fig2, ax2 = plt.subplots()
for layer_name in layers_1:
    layers_1[layer_name]['wgs84'].plot(ax=ax2, x='along_track', linewidth=1, linestyle=':', label=layer_name)


fig2.savefig(f"Petermann_{frame_1.attrs['granule']}_profiles.png", dpi=300)


def extract_layer_peak_power(radar_ds, layer_twtt, margin_twtt):
    """
    Extract the peak power of a radar layer within a specified margin around the layer's two-way travel time (TWTT).

    Parameters:
    - radar_ds: xarray Dataset containing radar data.
    - layer_twtt: The two-way travel time of the layer to extract.
    - margin_twtt: The margin around the layer's TWTT to consider for peak power extraction.

    Returns:
    - A tuple of (peak_twtt, peak_power) DataArrays, or (NaN arrays, NaN arrays) if no valid data.
    """

    # Ensure that layer_twtt.slow_time matches the radar_ds slow_time
    t_start = np.minimum(radar_ds.slow_time.min(), layer_twtt.slow_time.min())
    t_end = np.maximum(radar_ds.slow_time.max(), layer_twtt.slow_time.max())
    layer_twtt = layer_twtt.sel(slow_time=slice(t_start, t_end))
    radar_ds = radar_ds.sel(slow_time=slice(t_start, t_end))
    layer_twtt = layer_twtt.reindex(slow_time=radar_ds.slow_time, method='nearest', tolerance=pd.Timedelta(seconds=1), fill_value=np.nan)

    # Calculate the start and end TWTT for the margin
    start_twtt = layer_twtt - margin_twtt
    end_twtt = layer_twtt + margin_twtt

    # Extract the data within the specified TWTT range
    data_within_margin = radar_ds.where((radar_ds.twtt >= start_twtt) & (radar_ds.twtt <= end_twtt), drop=True)

    # Handle empty data (no overlap between layer TWTT and radar data TWTT range)
    if data_within_margin.twtt.size == 0:
        nan_array = xr.DataArray(
            np.full(radar_ds.slow_time.size, np.nan),
            dims=['slow_time'],
            coords={'slow_time': radar_ds.slow_time}
        )
        return nan_array.copy(), nan_array.copy()

    power_dB = 10 * np.log10(np.abs(data_within_margin.Data))

    # Find the twtt index corresponding to the peak power
    peak_twtt_index = power_dB.argmax(dim='twtt')
    # Convert the index to the actual TWTT value
    peak_twtt = power_dB.twtt[peak_twtt_index]

    # Calculate the peak power in dB
    peak_power = power_dB.isel(twtt=peak_twtt_index)

    # Remove unnecessary dimensions
    peak_twtt = peak_twtt.drop_vars('twtt')
    peak_power = peak_power.drop_vars('twtt')

    return peak_twtt, peak_power

def surface_bed_reflection_power(stac_item, opr=xopr.opr_access.OPRConnection()):

    frame = opr.load_frame(stac_item, data_product='CSARP_standard')
    frame = frame.resample(slow_time='5s').mean()

    layers = opr.get_layers(frame, source='auto', include_geometry=False)
    if layers is None or not layers:
        return None

    # Check that required layers are present
    if 'standard:surface' not in layers or 'standard:bottom' not in layers:
        return None

    # Check that layers have valid (non-NaN) twtt picks
    surface_twtt = layers['standard:surface']['twtt']
    bottom_twtt = layers['standard:bottom']['twtt']
    if surface_twtt.isnull().all() or bottom_twtt.isnull().all():
        return None

    # Re-pick surface and bed layers to ensure we're getting the peaks
    speed_of_light_in_ice = scipy.constants.c / np.sqrt(3.17)  # Speed of light in ice (m/s)
    layer_selection_margin_twtt = 50 / speed_of_light_in_ice # approx 50 m margin in ice
    surface_repicked_twtt, surface_power = extract_layer_peak_power(frame, layers["standard:surface"]['twtt'], layer_selection_margin_twtt)
    bed_repicked_twtt, bed_power = extract_layer_peak_power(frame, layers["standard:bottom"]['twtt'], layer_selection_margin_twtt)

    # Create a dataset from surface_repicked_twtt, bed_repicked_twtt, surface_power, and bed_power

    reflectivity_dataset = xr.merge([
        surface_repicked_twtt.rename('surface_twtt'),
        bed_repicked_twtt.rename('bed_twtt'),
        surface_power.rename('surface_power_dB'),
        bed_power.rename('bed_power_dB'),
        ],
        compat='override') # had to add this

    flight_line_metadata = frame.drop_vars(['Data', 'Surface'])
    reflectivity_dataset = xr.merge([reflectivity_dataset, flight_line_metadata])

    reflectivity_dataset = reflectivity_dataset.drop_dims(['twtt'])  # Remove the twtt dimension since everything has been flattened

    attributes_to_copy = ['season', 'segment', 'doi', 'ror', 'funder_text']
    reflectivity_dataset.attrs = {attr: frame.attrs[attr] for attr in attributes_to_copy if attr in frame.attrs}

    return reflectivity_dataset


reflectivity = surface_bed_reflection_power(stac_items.loc['Data_20100420_03_009'], opr=opr)


reflectivity


layers_1['standard:surface']['surface_power_dB'] = reflectivity['surface_power_dB']
layers_1['standard:bottom']['bed_power_dB'] = reflectivity['bed_power_dB']


layers_1['standard:bottom']


# Plot layers using elevation data
fig2, (ax2, ax3) = plt.subplots(nrows=2, ncols=1, figsize=(8,6))
for layer_name in layers_1:
    layers_1[layer_name]['wgs84'].plot(ax=ax2, x='slow_time', linewidth=1, linestyle=':', label=layer_name)

# Plot layers using elevation data
#ax2 plot
reflectivity = surface_bed_reflection_power(stac_items.loc['Data_20100420_03_009'], opr=opr)
bed_power_grad = np.gradient(reflectivity['bed_power_dB'])
reflectivity['bed_power_grad'] = (('slow_time'), bed_power_grad)
ax2.set_title('Petermann Grounding Point Example')


#ax3 plot
reflectivity['bed_power_grad'].plot(ax=ax3, x='slow_time', label='bed_grad', color='tab:green')
grad_max_idx = reflectivity['bed_power_grad'].argmax(dim="slow_time").data
grad_slowtime = reflectivity['bed_power_grad']['slow_time'][grad_max_idx]
bed_point = layers_1['standard:bottom']['wgs84'].sel(slow_time=grad_slowtime.data, method='nearest')

ax2.scatter(bed_point['slow_time'], bed_point.data, color='r', s=20, label="Grounding Point")

ax3.set_ylabel('Power [dB]')
ax2.legend()
ax3.legend()
ax3.set_title('')

fig2.savefig('auto_grounding_point_example.png')


# Plot layers using elevation data
ax3 = ax2.twinx()

reflectivity = surface_bed_reflection_power(stac_items.loc['Data_20100420_03_009'], opr=opr)
bed_power_grad = np.gradient(reflectivity['bed_power_dB'])
reflectivity['bed_power_grad'] = (('slow_time'), bed_power_grad)

reflectivity['surface_power_dB'].plot(ax=ax3, x='slow_time', label='Surface')
reflectivity['bed_power_dB'].plot(ax=ax3, x='slow_time', label='Bed')
ax3.set_ylabel('Power [dB]')
ax3.legend()


reflectivity['bed_power_grad'].argmax(dim="slow_time").data


slow_time_grad = reflectivity['bed_power_grad']['slow_time'][62]
slow_time_grad.data


bed_point = layers_1['standard:bottom']['wgs84'].sel(slow_time=slow_time_grad.data, method='nearest')
bed_point['slow_time']


fig3, (ax4, ax5) = plt.subplots(nrows=2, ncols=1, figsize=(8,6))
for layer_name in layers_1:
    layers_1[layer_name]['wgs84'].plot(ax=ax4, x='slow_time', linewidth=1, linestyle=':', label=layer_name)

surface_grad = np.gradient(layers_1['standard:surface']['wgs84'])
layers_1['standard:surface']['surface_grad'] = (('slow_time'), surface_grad)
layers_1['standard:surface']['surface_grad'].plot(ax=ax5, x='slow_time', linewidth=1, linestyle=':', label='surface grad')


layers_1['standard:surface']


surface_grad



